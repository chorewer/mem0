import os
import sys
import logging
from typing import List, Dict, Any
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from test_opensearch.opensearch_adapter import OpenSearchAdapter
from mem0.embeddings.volce_embedding import VolceEmbedding
from mem0.configs.embeddings.base import BaseEmbedderConfig

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(os.path.join(os.path.dirname(os.path.dirname(__file__)), ".env"))

class VolceOpenSearchIntegrationTestFixed:
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ"""
        # OpenSearch é…ç½®
        self.host = os.getenv("HOST_OPENSEARCH")
        self.port = os.getenv("PORT_OPENSEARCH")
        self.user = os.getenv("USER_OPENSEARCH")
        self.password = os.getenv("PASSWORD_OPENSEARCH")
        self.index = os.getenv("INDEX", "test_volce_integration_fixed")
        
        # Volce embedding é…ç½®
        self.volce_api_key = os.getenv("VOLCE_EMBED_API_KEY", "")
        self.volce_endpoint = os.getenv("VOLCE_EMBEDDING_ENDPOINT", "")
        self.volce_model = os.getenv("VOLCE_MODEL", "intfloat/multilingual-e5-small")
        
        # æ‰“å°é…ç½®ä¿¡æ¯ç”¨äºè°ƒè¯•
        print(f"è°ƒè¯•ä¿¡æ¯:")
        print(f"  Volce API Key: {'å·²è®¾ç½®' if self.volce_api_key else 'æœªè®¾ç½®'}")
        print(f"  Volce Endpoint: {self.volce_endpoint}")
        print(f"  Volce Model: {self.volce_model}")
        
        # åˆå§‹åŒ– embedding æœåŠ¡
        self.embedding_config = BaseEmbedderConfig(
            volce_api_key=self.volce_api_key,
            volce_endpoint=self.volce_endpoint,
            volce_model=self.volce_model
        )
        self.embedder = VolceEmbedding(config=self.embedding_config)
        
        # ä½¿ç”¨é€‚é…å™¨è€Œä¸æ˜¯ç›´æ¥ä½¿ç”¨OpenSearchDB
        self.db = OpenSearchAdapter(
            host=self.host,
            port=self.port,
            user=self.user,
            password=self.password,
            verify_certs=False,
            use_ssl=True,
            collection_name=self.index,
            embedding_model_dims=384,  # multilingual-e5-small æ˜¯ 384 ç»´
        )
        
        # æµ‹è¯•æ•°æ®
        self.test_documents = [
            {
                "text": "OpenAIå‘å¸ƒäº†GPT-4ï¼Œè¿™æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œå…·æœ‰å‡ºè‰²çš„æ¨ç†èƒ½åŠ›ã€‚",
                "category": "AIæŠ€æœ¯",
                "source": "OpenAI",
                "user_id": "user1"
            },
            {
                "text": "å‘é‡æ•°æ®åº“æ˜¯å­˜å‚¨å’Œæ£€ç´¢é«˜ç»´å‘é‡æ•°æ®çš„ä¸“é—¨æ•°æ®åº“ï¼Œå¸¸ç”¨äºç›¸ä¼¼æ€§æœç´¢ã€‚",
                "category": "æ•°æ®åº“æŠ€æœ¯",
                "source": "æŠ€æœ¯æ–‡æ¡£",
                "user_id": "user2"
            },
            {
                "text": "æœºå™¨å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒéœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºå’Œé«˜è´¨é‡çš„æ•°æ®é›†ã€‚",
                "category": "æœºå™¨å­¦ä¹ ",
                "source": "å­¦æœ¯è®ºæ–‡",
                "user_id": "user1"
            },
            {
                "text": "è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯åœ¨æœç´¢å¼•æ“ã€èŠå¤©æœºå™¨äººç­‰åº”ç”¨ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚",
                "category": "NLP",
                "source": "æŠ€æœ¯åšå®¢",
                "user_id": "user3"
            },
            {
                "text": "æ·±åº¦å­¦ä¹ ç¥ç»ç½‘ç»œå¯ä»¥è‡ªåŠ¨å­¦ä¹ æ•°æ®ä¸­çš„å¤æ‚æ¨¡å¼å’Œç‰¹å¾ã€‚",
                "category": "æ·±åº¦å­¦ä¹ ",
                "source": "æ•™ç¨‹",
                "user_id": "user2"
            }
        ]

    def test_embedding_generation(self):
        """æµ‹è¯• Volce embedding ç”Ÿæˆ"""
        print("\n=== æµ‹è¯• Volce Embedding ç”Ÿæˆ ===")
        try:
            test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºéªŒè¯ embedding ç”ŸæˆåŠŸèƒ½ã€‚"
            print(f"æµ‹è¯•æ–‡æœ¬: {test_text}")
            
            # æ£€æŸ¥é…ç½®
            if not self.volce_endpoint:
                print("âŒ Volce endpoint æœªé…ç½®")
                return None
            if not self.volce_api_key:
                print("âŒ Volce API key æœªé…ç½®")
                return None
                
            print(f"æ­£åœ¨è°ƒç”¨ Volce API: {self.volce_endpoint}")
            embedding = self.embedder.embed(test_text)
            
            if embedding is None:
                print("âŒ Embedding ç”Ÿæˆè¿”å› None")
                return None
            
            print(f"âœ… Embedding ç”ŸæˆæˆåŠŸ")
            print(f"   å‘é‡ç»´åº¦: {len(embedding)}")
            print(f"   å‘é‡ç±»å‹: {type(embedding)}")
            print(f"   å‘é‡å‰5ç»´: {embedding[:5]}")
            
            return embedding
        except Exception as e:
            print(f"âŒ Embedding ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def test_opensearch_setup(self):
        """æµ‹è¯• OpenSearch è®¾ç½®"""
        print("\n=== æµ‹è¯• OpenSearch è®¾ç½® ===")
        try:
            # åˆ›å»ºç´¢å¼•
            self.db.create_index()
            print("âœ… OpenSearch ç´¢å¼•åˆ›å»ºæˆåŠŸ")
            
            # åˆ—å‡ºé›†åˆ
            collections = self.db.list_cols()
            print(f"âœ… å½“å‰é›†åˆ: {collections}")
            
            return True
        except Exception as e:
            print(f"âŒ OpenSearch è®¾ç½®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def test_document_indexing(self):
        """æµ‹è¯•æ–‡æ¡£ç´¢å¼•"""
        print("\n=== æµ‹è¯•æ–‡æ¡£ç´¢å¼• ===")
        try:
            vectors = []
            payloads = []
            ids = []
            
            print(f"å½“å‰ä½¿ç”¨çš„ç´¢å¼•åç§°: {self.db.collection_name}")
            
            for i, doc in enumerate(self.test_documents):
                print(f"æ­£åœ¨å¤„ç†æ–‡æ¡£ {i+1}: {doc['text'][:50]}...")
                
                # ç”Ÿæˆ embedding
                try:
                    embedding = self.embedder.embed(doc["text"], memory_action="add")
                    
                    # ä¸¥æ ¼éªŒè¯å‘é‡
                    if embedding is None:
                        print(f"âŒ æ–‡æ¡£ {i+1} embedding ç”Ÿæˆå¤±è´¥ - è¿”å›None")
                        continue
                    
                    if not isinstance(embedding, list):
                        print(f"âŒ æ–‡æ¡£ {i+1} embedding ç±»å‹é”™è¯¯: {type(embedding)}")
                        continue
                    
                    if len(embedding) == 0:
                        print(f"âŒ æ–‡æ¡£ {i+1} embedding ä¸ºç©ºåˆ—è¡¨")
                        continue
                    
                    if len(embedding) != 384:
                        print(f"âŒ æ–‡æ¡£ {i+1} embedding ç»´åº¦é”™è¯¯: {len(embedding)}, æœŸæœ›384")
                        continue
                    
                    if None in embedding:
                        print(f"âŒ æ–‡æ¡£ {i+1} embedding åŒ…å«Noneå€¼")
                        continue
                    
                    if not all(isinstance(x, (int, float)) for x in embedding):
                        print(f"âŒ æ–‡æ¡£ {i+1} embedding åŒ…å«éæ•°å€¼")
                        continue
                    
                    print(f"   âœ… æ–‡æ¡£ {i+1}: å‘é‡éªŒè¯é€šè¿‡ (ç»´åº¦: {len(embedding)})")
                    
                    vectors.append(embedding)
                    payloads.append({
                        "text": doc["text"],
                        "category": doc["category"],
                        "source": doc["source"],
                        "user_id": doc["user_id"]
                    })
                    ids.append(f"doc_{i+1}")
                    
                except Exception as e:
                    print(f"âŒ æ–‡æ¡£ {i+1} embedding ç”Ÿæˆå¼‚å¸¸: {e}")
                    import traceback
                    traceback.print_exc()
                    continue
            
            if not vectors:
                print("âŒ æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•å‘é‡")
                return []
            
            print(f"\nå‡†å¤‡æ’å…¥æ•°æ®:")
            print(f"  æˆåŠŸå¤„ç†çš„æ–‡æ¡£æ•°: {len(vectors)}")
            print(f"  ç›®æ ‡ç´¢å¼•: {self.db.collection_name}")
            print(f"  ç´¢å¼•é…ç½®çš„å‘é‡ç»´åº¦: {self.db.embedding_model_dims}")
            
            # æœ€åä¸€æ¬¡éªŒè¯æ‰€æœ‰å‘é‡
            for i, vec in enumerate(vectors):
                if vec is None or len(vec) != 384:
                    print(f"âŒ æ’å…¥å‰å‘ç°é—®é¢˜å‘é‡ {i}: type={type(vec)}, len={len(vec) if vec else 'None'}")
                    return []
            
            # æ‰¹é‡æ’å…¥
            print(f"æ­£åœ¨æ’å…¥ {len(vectors)} ä¸ªå‘é‡åˆ° OpenSearch...")
            result = self.db.insert(vectors=vectors, payloads=payloads, ids=ids)
            print(f"âœ… æˆåŠŸç´¢å¼• {len(vectors)} ä¸ªæ–‡æ¡£")
            
            return ids
        except Exception as e:
            print(f"âŒ æ–‡æ¡£ç´¢å¼•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []

    def test_index_debug(self):
        """è°ƒè¯•ç´¢å¼•çŠ¶æ€"""
        print("\n=== è°ƒè¯•ç´¢å¼•çŠ¶æ€ ===")
        try:
            debug_info = self.db.debug_index()
            
            print(f"ç´¢å¼•è°ƒè¯•ä¿¡æ¯:")
            print(f"  æ–‡æ¡£æ€»æ•°: {debug_info.get('total_docs', 'N/A')}")
            
            if 'sample_docs' in debug_info:
                samples = debug_info['sample_docs']
                print(f"  æ ·æœ¬æ–‡æ¡£æ•°é‡: {len(samples)}")
                for i, doc in enumerate(samples[:2]):
                    print(f"    æ–‡æ¡£ {i+1}:")
                    print(f"      ID: {doc['_source'].get('id', 'N/A')}")
                    print(f"      å‘é‡å­—æ®µ: {'å­˜åœ¨' if 'vector_field' in doc['_source'] else 'ç¼ºå¤±'}")
                    if 'vector_field' in doc['_source']:
                        vec = doc['_source']['vector_field']
                        print(f"      å‘é‡ç»´åº¦: {len(vec) if isinstance(vec, list) else 'Not a list'}")
            
            return debug_info
        except Exception as e:
            print(f"âŒ ç´¢å¼•è°ƒè¯•å¤±è´¥: {e}")
            return {}

    def test_semantic_search(self):
        """æµ‹è¯•è¯­ä¹‰æœç´¢"""
        print("\n=== æµ‹è¯•è¯­ä¹‰æœç´¢ ===")
        
        search_queries = [
            "å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›",
            "å‘é‡æœç´¢æŠ€æœ¯", 
            "æ·±åº¦å­¦ä¹ è®­ç»ƒ",
            "NLPåº”ç”¨åœºæ™¯"
        ]
        
        try:
            for query in search_queries:
                print(f"\nğŸ” æŸ¥è¯¢: {query}")
                
                # ç”ŸæˆæŸ¥è¯¢å‘é‡
                query_embedding = self.embedder.embed(query, memory_action="search")
                
                if query_embedding is None:
                    print(f"   âŒ æŸ¥è¯¢å‘é‡ç”Ÿæˆå¤±è´¥")
                    continue
                
                # å…ˆå°è¯•å›ºå®šçš„æœç´¢æ–¹æ³•
                print("   å°è¯•é€‚é…å™¨æœç´¢æ–¹æ³•...")
                results = self.db.search(
                    query=query,
                    vectors=query_embedding,
                    limit=3
                )
                
                if results:
                    print(f"   âœ… æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³ç»“æœ:")
                    for i, result in enumerate(results):
                        print(f"   {i+1}. [Score: {result.score:.4f}] {result.payload['text'][:60]}...")
                        print(f"       ç±»åˆ«: {result.payload['category']}, æ¥æº: {result.payload['source']}")
                else:
                    print("   å°è¯•å¤‡ç”¨æœç´¢æ–¹æ³•...")
                    results = self.db.search_alternative(
                        query=query,
                        vectors=query_embedding,
                        limit=3
                    )
                    
                    if results:
                        print(f"   âœ… å¤‡ç”¨æ–¹æ³•æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³ç»“æœ:")
                        for i, result in enumerate(results):
                            print(f"   {i+1}. [Score: {result.score:.4f}] {result.payload['text'][:60]}...")
                            print(f"       ç±»åˆ«: {result.payload['category']}, æ¥æº: {result.payload['source']}")
                    else:
                        print("   âŒ ä¸¤ç§æœç´¢æ–¹æ³•éƒ½æœªæ‰¾åˆ°ç»“æœ")
                
        except Exception as e:
            print(f"âŒ è¯­ä¹‰æœç´¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    def test_list_documents(self):
        """æµ‹è¯•åˆ—å‡ºæ–‡æ¡£"""
        print("\n=== æµ‹è¯•åˆ—å‡ºæ–‡æ¡£ ===")
        try:
            # ä½¿ç”¨ä¿®å¤çš„listæ–¹æ³•
            all_docs = self.db.list(limit=10)
            print(f"âœ… ä½¿ç”¨é€‚é…å™¨åˆ—å‡ºæ–‡æ¡£: {len(all_docs)} ä¸ª")
            
            if all_docs:
                print("å‰3ä¸ªæ–‡æ¡£:")
                for i, doc in enumerate(all_docs[:3]):
                    print(f"  {i+1}. ID: {doc.id}")
                    print(f"     ç±»åˆ«: {doc.payload.get('category', 'N/A')}")
                    print(f"     æ–‡æœ¬: {doc.payload.get('text', 'N/A')[:50]}...")
            
            return all_docs
        except Exception as e:
            print(f"âŒ åˆ—å‡ºæ–‡æ¡£å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []

    def cleanup(self):
        """æ¸…ç†æµ‹è¯•æ•°æ®"""
        print("\n=== æ¸…ç†æµ‹è¯•æ•°æ® ===")
        try:
            choice = input("æ˜¯å¦è¦æ¸…ç†æµ‹è¯•æ•°æ®ï¼Ÿ(y/N): ").lower()
            if choice == 'y':
                self.db.reset()
                print("âœ… æµ‹è¯•æ•°æ®æ¸…ç†å®Œæˆ")
            else:
                print("âš ï¸ è·³è¿‡æ•°æ®æ¸…ç†")
        except Exception as e:
            print(f"âŒ æ¸…ç†å¤±è´¥: {e}")

    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹ Volce + OpenSearch ç»¼åˆæµ‹è¯• (ä½¿ç”¨é€‚é…å™¨)...\n")
        print(f"é…ç½®ä¿¡æ¯:")
        print(f"  OpenSearch: {self.host}:{self.port}")
        print(f"  ç´¢å¼•: {self.index}")
        print(f"  Volceæ¨¡å‹: {self.volce_model}")
        print(f"  å‘é‡ç»´åº¦: 384")
        
        # 1. æµ‹è¯• embedding ç”Ÿæˆ
        embedding = self.test_embedding_generation()
        if not embedding:
            print("âŒ Embedding æµ‹è¯•å¤±è´¥ï¼Œåœæ­¢åç»­æµ‹è¯•")
            return
        
        # 2. æµ‹è¯• OpenSearch è®¾ç½®
        if not self.test_opensearch_setup():
            print("âŒ OpenSearch è®¾ç½®å¤±è´¥ï¼Œåœæ­¢åç»­æµ‹è¯•")
            return
        
        # 3. æµ‹è¯•æ–‡æ¡£ç´¢å¼•
        doc_ids = self.test_document_indexing()
        if not doc_ids:
            print("âŒ æ–‡æ¡£ç´¢å¼•å¤±è´¥ï¼Œåœæ­¢åç»­æµ‹è¯•")
            return
        
        # 4. è°ƒè¯•ç´¢å¼•çŠ¶æ€
        self.test_index_debug()
        
        # 5. æµ‹è¯•åˆ—å‡ºæ–‡æ¡£
        self.test_list_documents()
        
        # 6. æµ‹è¯•è¯­ä¹‰æœç´¢
        self.test_semantic_search()
        
        # 7. æ¸…ç†ï¼ˆå¯é€‰ï¼‰
        self.cleanup()
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    tester = VolceOpenSearchIntegrationTestFixed()
    tester.run_all_tests() 